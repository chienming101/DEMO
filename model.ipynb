{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2016 Matthew Earl\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "#     The above copyright notice and this permission notice shall be included\n",
    "#     in all copies or substantial portions of the Software.\n",
    "# \n",
    "#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n",
    "#     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "#     MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n",
    "#     NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n",
    "#     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n",
    "#     OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n",
    "#     USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Definition of the neural networks. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "__all__ = (\n",
    "    'get_training_model',\n",
    "    'get_detect_model',\n",
    "    'WINDOW_SHAPE',\n",
    ")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import common\n",
    "\n",
    "\n",
    "WINDOW_SHAPE = (64, 128)\n",
    "\n",
    "\n",
    "# Utility functions\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, W, stride=(1, 1), padding='SAME'):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride[0], stride[1], 1],\n",
    "                      padding=padding)\n",
    "\n",
    "\n",
    "def max_pool(x, ksize=(2, 2), stride=(2, 2)):\n",
    "  return tf.nn.max_pool(x, ksize=[1, ksize[0], ksize[1], 1],\n",
    "                        strides=[1, stride[0], stride[1], 1], padding='SAME')\n",
    "\n",
    "\n",
    "def avg_pool(x, ksize=(2, 2), stride=(2, 2)):\n",
    "  return tf.nn.avg_pool(x, ksize=[1, ksize[0], ksize[1], 1],\n",
    "                        strides=[1, stride[0], stride[1], 1], padding='SAME')\n",
    "\n",
    "\n",
    "def convolutional_layers():\n",
    "    \"\"\"\n",
    "    Get the convolutional layers of the model.\n",
    "\n",
    "    \"\"\"\n",
    "    x = tf.placeholder(tf.float32, [None, None, None])\n",
    "\n",
    "    # First layer\n",
    "    W_conv1 = weight_variable([5, 5, 1, 48])\n",
    "    b_conv1 = bias_variable([48])\n",
    "    x_expanded = tf.expand_dims(x, 3)\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_expanded, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool(h_conv1, ksize=(2, 2), stride=(2, 2))\n",
    "\n",
    "    # Second layer\n",
    "    W_conv2 = weight_variable([5, 5, 48, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool(h_conv2, ksize=(2, 1), stride=(2, 1))\n",
    "\n",
    "    # Third layer\n",
    "    W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "    b_conv3 = bias_variable([128])\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    h_pool3 = max_pool(h_conv3, ksize=(2, 2), stride=(2, 2))\n",
    "\n",
    "    return x, h_pool3, [W_conv1, b_conv1,\n",
    "                        W_conv2, b_conv2,\n",
    "                        W_conv3, b_conv3]\n",
    "\n",
    "\n",
    "def get_training_model():\n",
    "    \"\"\"\n",
    "    The training model acts on a batch of 128x64 windows, and outputs a (1 +\n",
    "    7 * len(common.CHARS) vector, `v`. `v[0]` is the probability that a plate is\n",
    "    fully within the image and is at the correct scale.\n",
    "    \n",
    "    `v[1 + i * len(common.CHARS) + c]` is the probability that the `i`'th\n",
    "    character is `c`.\n",
    "\n",
    "    \"\"\"\n",
    "    x, conv_layer, conv_vars = convolutional_layers()\n",
    "    \n",
    "    # Densely connected layer\n",
    "    W_fc1 = weight_variable([32 * 8 * 128, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "\n",
    "    conv_layer_flat = tf.reshape(conv_layer, [-1, 32 * 8 * 128])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(conv_layer_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # Output layer\n",
    "    W_fc2 = weight_variable([2048, 1 + 7 * len(common.CHARS)])\n",
    "    b_fc2 = bias_variable([1 + 7 * len(common.CHARS)])\n",
    "\n",
    "    y = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "    return (x, y, conv_vars + [W_fc1, b_fc1, W_fc2, b_fc2])\n",
    "\n",
    "\n",
    "def get_detect_model():\n",
    "    \"\"\"\n",
    "    The same as the training model, except it acts on an arbitrarily sized\n",
    "    input, and slides the 128x64 window across the image in 8x8 strides.\n",
    "\n",
    "    The output is of the form `v`, where `v[i, j]` is equivalent to the output\n",
    "    of the training model, for the window at coordinates `(8 * i, 4 * j)`.\n",
    "\n",
    "    \"\"\"\n",
    "    x, conv_layer, conv_vars = convolutional_layers()\n",
    "    \n",
    "    # Fourth layer\n",
    "    W_fc1 = weight_variable([8 * 32 * 128, 2048])\n",
    "    W_conv1 = tf.reshape(W_fc1, [8,  32, 128, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "    h_conv1 = tf.nn.relu(conv2d(conv_layer, W_conv1,\n",
    "                                stride=(1, 1), padding=\"VALID\") + b_fc1) \n",
    "    # Fifth layer\n",
    "    W_fc2 = weight_variable([2048, 1 + 7 * len(common.CHARS)])\n",
    "    W_conv2 = tf.reshape(W_fc2, [1, 1, 2048, 1 + 7 * len(common.CHARS)])\n",
    "    b_fc2 = bias_variable([1 + 7 * len(common.CHARS)])\n",
    "    h_conv2 = conv2d(h_conv1, W_conv2) + b_fc2\n",
    "\n",
    "    return (x, h_conv2, conv_vars + [W_fc1, b_fc1, W_fc2, b_fc2])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
